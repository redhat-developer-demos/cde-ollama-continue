schemaVersion: 2.2.0
metadata:
  name: ollama-continue-udi
attributes:
  controller.devfile.io/storage-type: ephemeral # TODO try to remove this next
# projects:
#   - name: devspaces-ollama-continue
#     git:
#       remotes:
#         origin: 'https://github.com/manhah/devspaces-ollama-continue.git' # TODO Adapt this to the final repo when done
#       checkoutFrom:
#         revision: feature/base # TODO Adapt this to a dedicated version (or main) when done
components:
- name: udi
  container:
    image: quay.io/devfile/universal-developer-image:ubi8-latest
    memoryLimit: 4Gi
    memoryRequest: 2Gi
    cpuLimit: 4000m
    cpuRequest: 1000m
    mountSources: true
    sourceMapping: /projects
- name: ollama
  attributes:
    container-overrides:
      resources:
        limits:
          cpu: 4000m
          memory: 12Gi
          # nvidia.com/gpu: 1 # Uncomment this if the pod shall be scheduled only on a GPU node
        requests:
          cpu: 1000m
          memory: 8Gi
          # nvidia.com/gpu: 1 # Uncomment this if the pod shall be scheduled only on a GPU node
  container:
    image: docker.io/ollama/ollama:latest
    mountSources: true
    sourceMapping: /.ollama
# commands:
#   - id: pullmodel
#     exec:
#       component: ollama
#       commandLine: "ollama pull codellama:13b"
#   - id: copyconfig
#     exec:
#       component: udi
#       commandLine: "mkdir /home/user/.continue && cp /projects/devspaces-ollama-continue/continue-config.json /home/user/.continue/config.json"
# events:
#   postStart:
#     - pullmodel
#     - copyconfig
